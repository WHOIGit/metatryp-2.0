from proteomics.models import (Peptide, Specialized_Assembly, Specialized_Assembly_Sequence)from proteomics import dbfrom proteomics.util.digest import cleavefrom proteomics.util.logging_util import LoggerLogHandlerfrom proteomics.util.mass import get_aa_sequence_massfrom proteomics.util import fasta#from proteomics.services.annotations import extract_venter_annotationsfrom proteomics.config import VALID_AASimport osimport hashlibimport loggingfrom collections import defaultdictimport timeclass DigestAndIngestSpecializedAssemblyTask(object):    def __init__(self, logger=logging.getLogger(), fasta_paths=[],                 digest=None, get_connection=None, **kwargs):        self.logger = logger        self.fasta_paths = fasta_paths        self.digest = digest        self.get_connection = get_connection        self.total_peptide_time = 0;    def run(self):        # Initialize stats dict.        self.stats = defaultdict(int)        # Process FASTA files.        for path in self.fasta_paths:            self.process_fasta_file(path)        self.logger.info("Digest and ingest task complete.")        return self.stats    def process_fasta_file(self, path):        base_msg = "Processing file '%s'..." % path        file_logger = self.get_child_logger(id(path), base_msg,                                            self.logger)        # Get specialized assembly name from filename.        # This may not be the best way to do this, might be better to allow user to input a name?        fasta_file_name = os.path.splitext(os.path.basename(path))[0]        print("FASTA FILE",fasta_file_name)        cur = db.get_psycopg2_cursor();        cur.execute("select sa.id from specialized_assembly sa where sa.fasta_file_key = %s;", (fasta_file_name,))        specialized_assembly_result = cur.fetchone()        db.psycopg2_connection.commit()        if specialized_assembly_result is None:            # add assembly to the DB            # db.psycopg2_connection.commit()            self.stats['Specialized Assembly'] += 1            file_logger.info("Created Specialized Assembly '%s'" % fasta_file_name)        else:            specialized_assembly = Specialized_Assembly(id=specialized_assembly_result[0], fasta_file_key=fasta_file_name)            # Check if specialized assembly has already been digested with given digestion agent.            cur.execute(                "select sad.digest_id from specialized_assembly_digest_peptide sad where sad.specialized_assembly_sequence_id in (select sas.id from specialized_assembly_sequence sas where sas.specialized_assembly_id = %s) and sad.digest_id = %s;",                (specialized_assembly.id, self.digest.id,))            db.psycopg2_connection.commit()        # Process specialized assembly sequences in batches.        file_logger.info("Counting # of specialized assembly sequences...")        num_proteins = 0        for metadata, sequence in fasta.read(path):            num_proteins += 1        file_logger.info("%s total specialized assembly sequences." % num_proteins)        batch_size = 3000        batch_counter = 0        batch = []        curr_genome_name = "";        type_flag = "MAG"  # automate this in future        study_name = "Delmont_TARA_MAGs"  # automate this in future, or perhaps get from command line        protein_logger = self.get_child_logger(            "%s_proteins" % id(file_logger), "Processing specialized assembly sequences...",            file_logger        )        protein_logger.info("")        for metadata, sequence in fasta.read(path):            genome_name = metadata.rsplit("_",1)[0]            #if unique name save new specialized_assembly            cur.execute("select sa.id from specialized_assembly sa where sa.genome_name = %s;", (genome_name,))            specialized_assembly_result = cur.fetchone()            db.psycopg2_connection.commit()            if specialized_assembly_result is None:                cur.execute("select * from specialized_assembly_insert(%s, %s,%s, %s);", (genome_name,fasta_file_name,type_flag,study_name)) #need to update db function                db.psycopg2_connection.commit()                specialized_assembly_result = cur.fetchone()            specialized_assembly = Specialized_Assembly(id=specialized_assembly_result[0],                                                        fasta_file_key=fasta_file_name)            if VALID_AAS.search(sequence):                file_logger.info("Tried to ingest invalid protein sequence %s" % sequence)            else:                batch.append((metadata, sequence,))                batch_counter += 1            if (batch_counter % batch_size) == 0:                self.process_specialized_assembly_sequence_batch(                    batch, specialized_assembly, logger=protein_logger)                protein_logger.info(                    ("%s of %s (%.1f%%)") % (                        batch_counter, num_proteins,                        100.0 * batch_counter / num_proteins                    )                )                batch = []        self.process_specialized_assembly_sequence_batch(            batch, specialized_assembly, logger=protein_logger)        protein_logger.info("Total Peptide Time: %s" % self.total_peptide_time)    def get_checksum(self, path):        sha1 = hashlib.sha1()        with open(path, 'rb') as f:            while True:                data = f.read(8192)                if not data: break                sha1.update(data)        return sha1.hexdigest()    def process_specialized_assembly_sequence_batch(self, batch, specialized_assembly, logger=None):        """ Process a batch of specialized assembly sequences with the given digest. """        if not batch:            return        if not logger:            logger = self.logger        # Get existing specialized sequences (proteins) by searching for sequences.        sequences = []        metadataList = []        for metadata, sequence in batch:            sequences.append(sequence)        # Initialize collection of undigested proteins.        undigested_sequences = {}        sa_sequences = []        sa_digest_ids = []        sa_ids = []        sa_accesion_ids = {}        # Create proteins which do not exist in the db and add to undigested        # collection.        start_time = time.time()        num_new_sequences = 0        for metadata, sequence in batch:            num_new_sequences += 1            # add sequence and mass to their respective lists to be passed to postgres stored procedure            sa_sequences.append(sequence)            metadataList.append(metadata)            sa_digest_ids.append(self.digest.id)            sa_ids.append(specialized_assembly.id)        logger.info("creating %s new specialized assembly sequences..." % (        num_new_sequences))        cur = db.get_psycopg2_cursor()        cur.execute("select * from specialized_assembly_sequence_insert(%s, %s, %s);",                    (sa_sequences, sa_ids, metadataList))        # iterate through the protein records returned from the insert and build a protein object        for record in cur:            try:                sa_seq = Specialized_Assembly_Sequence(id=record[0], sequence=record[1], specialized_assembly_id=record[2],                                               sequence_id=record[3])            except Exception as e:                logger.exception("Error processing specialized assembly sequence, skipping")                continue            undigested_sequences[record[0]] = sa_seq            sa_accesion_ids[sa_seq.sequence_id] = sa_seq.id;        db.psycopg2_connection.commit()        total_time = time.time() - start_time        logger.info("time elapsed: %s" % (total_time))        self.stats['Protein'] += num_new_sequences        # Digest undigested proteins.        if undigested_sequences:            logger.info("digesting %s proteins" % len(undigested_sequences))            undigested_batch = {}            peptide_counter = 0            for specialized_assembly_sequence in list(undigested_sequences.values()):                peptide_sequences = cleave(                    specialized_assembly_sequence.sequence,                    self.digest.protease.cleavage_rule,                    self.logger,                    self.digest.max_missed_cleavages,                    min_acids=self.digest.min_acids,                    max_acids=self.digest.max_acids,                )                peptide_counter += len(peptide_sequences)                undigested_batch[specialized_assembly_sequence.id] = {                    'peptide_sequences': peptide_sequences,                    'specialized_assembly_sequence': specialized_assembly_sequence,                    'digest': self.digest,                }            logger.info("undigested batch size %s" % len(undigested_batch))            self.process_peptide_batch(undigested_batch, logger)    def process_peptide_batch(self, specialized_assembly_sequence_digests_dict, logger=None):        if not logger:            logger = self.logger        # Assemble combined peptide sequences and specialized assembly digests.  Each specialized assembly sequence can have many peptides.        combined_peptide_sequences = set()        for proteinId, data in list(specialized_assembly_sequence_digests_dict.items()):            for sequence in data['peptide_sequences']:                combined_peptide_sequences.add(sequence)        # Get existing peptides.        existing_peptides = {}        # Create non-existent peptides in bulk.        start_time = time.time()        num_new_peptides = 0        peptide_sequences = []        peptide_masses = []        peptide_file = ''        for sequence in combined_peptide_sequences:                num_new_peptides += 1                #calculate mass of peptide                mass = get_aa_sequence_mass(sequence)                peptide_sequences.append(sequence)                peptide_masses.append(mass)        logger.info("Creating %s new peptides..." % num_new_peptides)        cur = db.get_psycopg2_cursor()        cur.execute("select * from peptide_insert(%s, %s);", (peptide_sequences, peptide_masses))        for record in cur:            try:                peptide = Peptide(id=record[0], sequence=record[1],)                existing_peptides[peptide.sequence] = peptide            except Exception as e:                logger.exception("Error processing peptide, skipping")                continue        total_time = time.time() - start_time        self.total_peptide_time = self.total_peptide_time + total_time;        logger.info("peptide time elapsed: %s" % (total_time))        self.stats['Peptide'] += num_new_peptides        # Create histogram of peptide sequence occurences for each protein.        num_peptide_instances = 0        for sequenceId, data in list(specialized_assembly_sequence_digests_dict.items()):            peptides_histogram = defaultdict(int)            for sequence in data['peptide_sequences']:                peptides_histogram[sequence] += 1            data['peptide_histogram'] = peptides_histogram            # Update number of peptide instances.            num_peptide_instances += len(peptides_histogram)        # Create protein digest peptide instances in bulk.        logger.info("Creating %s new specialized aseembly sequence digest peptides..." % (        num_peptide_instances))        start_time = time.time()        pdp_peptide_ids = []        pdp_sa_sequence_ids = []        pdp_digest_ids = []        pdp_peptide_count = []        pdp_counter = 0        for sequenceId, data in list(specialized_assembly_sequence_digests_dict.items()):            for sequence, count in list(data['peptide_histogram'].items()):                pdp_counter += 1                peptide = existing_peptides[sequence]                pdp_peptide_ids.append(peptide.id)                pdp_sa_sequence_ids.append(data['specialized_assembly_sequence'].id)                pdp_digest_ids.append(data['digest'].id)                pdp_peptide_count.append(count)        total_time = time.time() - start_time        cur.execute("select specialized_assembly_digest_peptide_insert(%s, %s, %s, %s);",                    (pdp_peptide_ids, pdp_sa_sequence_ids, pdp_digest_ids, pdp_peptide_count))        db.psycopg2_connection.commit()        total_time = time.time() - start_time       # logger.info("protein digest time elapsed: %s" % (total_time))        self.stats['ProteinDigestPeptide'] += num_peptide_instances    def get_child_logger(self, name=None, base_msg=None, parent_logger=None):        if not parent_logger:            parent_logger = self.logger        logger = logging.getLogger("%s_%s" % (id(self), name))        formatter = logging.Formatter(base_msg + ' %(message)s.')        log_handler = LoggerLogHandler(parent_logger)        log_handler.setFormatter(formatter)        logger.addHandler(log_handler)        logger.setLevel(parent_logger.level)        return logger